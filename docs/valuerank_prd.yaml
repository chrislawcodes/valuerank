# =========================================================
# ValueRank | PRD (Synced from Google Doc)
# Source: https://docs.google.com/document/d/1LzDtvGhGyH88JaIgNWkbwqMElk9MW7pWgqwCZE4WhyU
# Last Updated: 2026-02-19
# =========================================================

meta:
  version: "Cloud Platform V1"
  mission: "Map the behavioral profiles of AI systems"

# ---------------------------------------------------------
# 1. Mission & Vision
# ---------------------------------------------------------
Vision:
  Mission: "Map the behavioral profiles of AI systems."
  Concept: "Today's AI models are black boxes... We rarely get a systematic, comparable map of how they actually behave across different situations."
  Goal: "Determine the human values embedded in AI decision-making by running vignette-based stress tests."
  Approach: "Scientific endeavor: Reproducible, Transparent, Neutral (no value judgements)."

# ---------------------------------------------------------
# 2. Methodology
# ---------------------------------------------------------
Methodology:
  Framework: "Schwartz framework of human values (currently testing 10 core values due to cost/efficiency, though the platform supports all 19)."
  Goals:
    1: "Find out which values each AI prioritizes."
    2: "Predict which value an AI will prioritize in a scenario."

  Vignette_Structure:
    1: "Domain Setup: Context sentence with an equal-footing clause to remove confounders."
    2: "Two options (A and B) representing conflicting values mapped to concrete entities."
    3: "Statement describing how strongly the subject cares about the value (1-5 scale)."
    4: "5-point choice scale: Strongly Support A (5) ... Neutral (3) ... Strongly Support B (1)"
    5: "Generic titles/subjects to avoid naming bias"

  Experimental_Design:
    - "Vary each value on a scale of 1-5."
    - "Result: 25 combinations (Conditions) for each vignette."
    - "Temperature: All target models are run at Temperature 0 to ensure deterministic preference signals rather than stochastic noise."
    - "Metric 1: Overall Win Rate (computed across all 25 grid responses to capture robustness of preference across varying intensity levels)."
    - "Metric 2: Bradley-Terry Pairwise Ranking (derived from the full win-rate matrix with BT-implied uncertainty)."

  Project_Procedure:
    Goal: "Deterministic Grid Sampling"
    - "Phase 1 (Estimation): Run the full 25-condition grid for each vignette exactly once per domain (N=1 per condition at Temp 0). Total: 1,125 trials per domain."
    - "Phase 2 (Validity Check): Verify manipulation works by ensuring corners (5,1) and (1,5) enforce intended directionality, and regression coefficients are properly signed."
    - "Phase 3 (Cross-domain Replication): Replicate across structurally distinct domains to test if value orderings hold, evaluating stable value profiles (e.g. via Kendall's Ï„)."

# ---------------------------------------------------------
# 3. Critical User Journeys
# ---------------------------------------------------------
User_Journeys:
  Flow: "Domain Expansion -> Vignette Creation -> Target AI Probing -> Analysis & Export"

  Initial_Setup:
    - "Preamble creation: Primes Target AIs to focus on moral reasoning via system prompts."
    - "Value Rubric: Selecting the values to test for the specific domain."

  Scenario_Creation:
    - "Author Vignettes securely in the React-based DevTool, defining dimensions (values) and extracting the full 5x5 baseline scenario grid."

  Execution_Engine:
    - "Orchestrate evaluation runs against target models (GPT-4o, Claude 3.5, Gemini 1.5, etc) via a highly-concurrent PostgreSQL/PgBoss job queue paired with Python execution workers (probe, summarize, analyze)."

  Evaluation_Phase:
    - "The Target AI is prompted to return a 1-5 rating directly."
    - "The summarize worker extracts this explicit numerical decision deterministically. There is no separate Judge AI; the models score themselves on the given scale."

  Analysis_Export:
    - "Review aggregate statistics (Win Rates, Pairwise Matrices) via the Web UI."
    - "Export compact datasets (CSV) or OData for unified external analysis (e.g., in Google Sheets)."

# ---------------------------------------------------------
# 4. Terminology
# ---------------------------------------------------------
Definitions:
  Domain: "A life context (e.g., Jobs, Neighborhoods, City Planning) that provides a natural binary-choice frame."
  Vignette: "The complete experimental narrative and unit of testing."
  Attribute: "Specific Schwartz human values (e.g., Universalism, Security)."
  Level: "Degree of prominence/weight assigned to an Attribute (1-5)."
  Condition: "A specific realization of a Vignette where Attribute levels are fixed (a cell in a 5x5 grid)."
  Trial: "Act of presenting a single Condition to a Target AI."
  Batch: "Complete execution of an experiment across conditions."

# ---------------------------------------------------------
# 5. Design Decisions
# ---------------------------------------------------------
Design:
  Values_Model: "Schwartz 10 Values chosen for the initial rollout and first wave of domain expansions for cost-efficiency. The system fundamentally models the full 19 values."
  Sample_Size: "Fixed deterministic sampling: N=1 per condition per vignette for Phase 1 runs (fallback to N=3 if non-determinism detected at Temp 0)."

# ---------------------------------------------------------
# 6. Roadmap & Priorities
# ---------------------------------------------------------
Roadmap:
  - "Robustness & Meta-Evaluation (manipulation validity checks, transitivity checks, framing floor effects)"
  - "Vignette Domain Expansion (Scaling to structurally distinct domains like Neighborhoods and City Planning to calculate cross-domain replication stable value profiles)"
  - "Deterministic Execution Architecture (Implement Temperature 0, 25-cell pooled win rate analysis)"
  - "Baseline Leaderboards (Publish pairwise win rate matrices and Bradley-Terry score rankings across frontier models)"

# =========================================================
# ValueRank | PRD (Synced from Google Doc)
# Source: https://docs.google.com/document/d/1LzDtvGhGyH88JaIgNWkbwqMElk9MW7pWgqwCZE4WhyU
# Last Updated: 2026-02-19
# =========================================================

meta:
  version: "Cloud Platform V1"
  mission: "Map the behavioral profiles of AI systems"

# ---------------------------------------------------------
# 1. Mission & Vision
# ---------------------------------------------------------
Vision:
  Mission: "Map the behavioral profiles of AI systems."
  Concept: "Today's AI models are black boxes... We rarely get a systematic, comparable map of how they actually behave across different situations."
  Goal: "Determine the human values embedded in AI decision-making by running vignette-based stress tests."
  Approach: "Scientific endeavor: Reproducible, Transparent, Neutral (no value judgements)."

# ---------------------------------------------------------
# 2. Methodology
# ---------------------------------------------------------
Methodology:
  Framework: "Schwartz framework of human values (currently testing 10 core values due to cost/efficiency, though the platform supports all 19)."
  Goals:
    1: "Find out which values each AI prioritizes."
    2: "Predict which value an AI will prioritize in a scenario."

  Vignette_Structure:
    1: "Domain Setup: Context sentence with an equal-footing clause to remove confounders."
    2: "Two options (A and B) representing conflicting values mapped to concrete entities."
    3: "Statement describing how strongly the subject cares about the value (1-5 scale)."
    4: "5-point choice scale: Strongly Support A (5) ... Neutral (3) ... Strongly Support B (1)"
    5: "Generic titles/subjects to avoid naming bias"

  Experimental_Design:
    - "Vary each value on a scale of 1-5."
    - "Result: 25 combinations (Conditions) for each vignette."
    - "Metric 1: Win Rate (prioritized / (prioritized + deprioritized))."
    - "Metric 2: Pairwise Matrix (how often one value beats another in direct conflict)."
    - "Diagnostic Metric: Unmatched Values (when models bypass the intended values)."

  Project_Procedure:
    Goal: "Smart Sampling"
    - "Focus on statistical convergence (where the win-rate matrix stabilizes) rather than fixed batch counts to optimize API costs."
    - "Run definitive baseline benchmarks across frontier models once convergence points are established."

# ---------------------------------------------------------
# 3. Critical User Journeys
# ---------------------------------------------------------
User_Journeys:
  Flow: "Domain Expansion -> Vignette Creation -> Target AI Probing -> Analysis & Export"

  Initial_Setup:
    - "Preamble creation: Primes Target AIs to focus on moral reasoning via system prompts."
    - "Value Rubric: Selecting the values to test for the specific domain."

  Scenario_Creation:
    - "Author Vignettes securely in the React-based DevTool, defining dimensions (values) and extracting the full 5x5 baseline scenario grid."

  Execution_Engine:
    - "Orchestrate evaluation runs against target models (GPT-4o, Claude 3.5, Gemini 1.5, etc) via a highly-concurrent PostgreSQL/PgBoss job queue paired with Python execution workers (probe, summarize, analyze)."

  Evaluation_Phase:
    - "The Target AI is prompted to return a 1-5 rating directly."
    - "The summarize worker extracts this explicit numerical decision deterministically. There is no separate Judge AI; the models score themselves on the given scale."

  Analysis_Export:
    - "Review aggregate statistics (Win Rates, Pairwise Matrices) via the Web UI."
    - "Export compact datasets (CSV) or OData for unified external analysis (e.g., in Google Sheets)."

# ---------------------------------------------------------
# 4. Terminology
# ---------------------------------------------------------
Definitions:
  Domain: "A life context (e.g., Jobs, Neighborhoods, City Planning) that provides a natural binary-choice frame."
  Vignette: "The complete experimental narrative and unit of testing."
  Attribute: "Specific Schwartz human values (e.g., Universalism, Security)."
  Level: "Degree of prominence/weight assigned to an Attribute (1-5)."
  Condition: "A specific realization of a Vignette where Attribute levels are fixed (a cell in a 5x5 grid)."
  Trial: "Act of presenting a single Condition to a Target AI."
  Batch: "Complete execution of an experiment across conditions."

# ---------------------------------------------------------
# 5. Design Decisions
# ---------------------------------------------------------
Design:
  Values_Model: "Schwartz 10 Values chosen for the initial rollout and first wave of domain expansions for cost-efficiency. The system fundamentally models the full 19 values."
  Sample_Size: "Dynamically determined by convergence point testing (Smart Sampling strategy)."

# ---------------------------------------------------------
# 6. Roadmap & Priorities
# ---------------------------------------------------------
Roadmap:
  - "Robustness & Meta-Evaluation (loophole analysis, prompt sensitivity)"
  - "Vignette Domain Expansion (Scaling to new contrasting domains like City Planning to test context-sensitivity)"
  - "Smart Sampling Execution (Implement statistical convergence testing)"
  - "Baseline Leaderboards (Publish comparative analysis across frontier models)"
